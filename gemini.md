# API-Manager Project Context

> **For AI Agents:** Read this file at the start of every conversation to understand the project.
> **Last Updated:** Feb 07, 2026 | **Status:** üü¢ ACTIVE

---

## üéØ Project Purpose

**Cricket News & Live Scores API** with automated content scraping, AI enhancement, and Twitter posting.

**Frontend URL:** https://play.urtechy.com  
**API Base (Production):** https://drop.urtechy.com/api/cricket  
**API Base (Local):** http://localhost:5003/api/cricket

---

## üèóÔ∏è Architecture Quick Reference

```
api-manager/
‚îú‚îÄ‚îÄ server.js                 # Express entry (Port 5003)
‚îú‚îÄ‚îÄ ecosystem.config.js       # PM2 configuration
‚îú‚îÄ‚îÄ routes/Cricket/index.js   # All API endpoints (3292 lines)
‚îú‚îÄ‚îÄ scrapers/                 # News scrapers + workers
‚îÇ   ‚îú‚îÄ‚îÄ live-score-worker.js  # PM2: Scrapes every 60s ‚Üí Redis
‚îÇ   ‚îú‚îÄ‚îÄ tweet-worker.js       # PM2 Cron: Posts to Twitter 4x/day
‚îÇ   ‚îú‚îÄ‚îÄ content-enhancer-claude.js  # AI enhancement (Gemini 3 Flash)
‚îÇ   ‚îú‚îÄ‚îÄ run-scraper.js        # Cricbuzz
‚îÇ   ‚îú‚îÄ‚îÄ run-espncricinfo-scraper.js
‚îÇ   ‚îú‚îÄ‚îÄ run-icc-scraper.js
‚îÇ   ‚îú‚îÄ‚îÄ run-bbc-scraper.js
‚îÇ   ‚îî‚îÄ‚îÄ run-iplt20-scraper.js
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ vps-scrape.sh         # CRON: Master orchestrator
‚îÇ   ‚îú‚îÄ‚îÄ prune-news.js         # Delete >90 day articles
‚îÇ   ‚îî‚îÄ‚îÄ clear_news_cache.js
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ twitter-service.js    # Twitter API integration
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ redis-client.js       # Upstash Redis (live scores cache)
‚îÇ   ‚îî‚îÄ‚îÄ apiErrors.js          # Error handling
‚îî‚îÄ‚îÄ prisma/schema.prisma      # Database models
```

---

## ‚öôÔ∏è Services & Automation

### PM2 Services (Always Running)
| Service | Script | Purpose |
|---------|--------|---------|
| `api-manager` | server.js | Express API server |
| `live-score-worker` | scrapers/live-score-worker.js | Scrapes Cricbuzz ‚Üí Redis every 60s |
| `tweet-worker` | scrapers/tweet-worker.js | Auto-posts tweets (cron: 4x daily) |

### Cron Jobs
| Schedule (UTC) | IST | Command |
|----------------|-----|---------|
| `30 0,6,9,12,15,18,21 * * *` | 6:00, 11:30, 15:00, 18:00, 21:00, 00:00, 3:00 | `vps-scrape.sh` (all scrapers + AI enhancer) |

---

## üì° API Endpoints

### Live Scores
- `GET /live-scores` - Currently live matches (from Redis)
- `GET /recent-scores` - Recently completed matches
- `GET /upcoming-matches` - Scheduled matches

### News
- `GET /news?limit=10&source=all` - News articles (database)
- `GET /news/:slug` - Single article

### Stats (RapidAPI)
- `GET /stats/rankings?category=batsmen&formatType=test`
- `GET /stats/standings?matchType=1`
- `GET /stats/records?statsType=mostRuns`

### Photos
- `GET /photos/list` - Photo galleries
- `GET /photos/gallery/:id` - Gallery details
- `GET /photos/image/i1/c{imageId}/i.jpg` - Image proxy

---

## üóÑÔ∏è Database Schema (Supabase PostgreSQL)

```prisma
model NewsArticle {
  id            String   @id
  slug          String   @unique  // SEO URL identifier
  title         String
  description   String?
  content       String?
  imageUrl      String?
  sourceUrl     String   @unique
  sourceId      String   @unique  // External source ID
  sourceName    String   // "Cricbuzz", "ESPN", "BBC", etc.
  tags          String[]
  sport         String   // "cricket"
  category      String?
  enhancedContent EnhancedContent?  // AI-generated content
}

model EnhancedContent {
  id              String   @id
  articleId       String   @unique
  title           String   // SEO title (60 chars)
  content         String   // Full markdown (300-500 words)
  metaDescription String   // SEO meta (155 chars)
  keyTakeaways    String[] // 3-5 bullet points
  tweetedAt       DateTime?  // When posted to Twitter (null = not tweeted)
  tweetId         String?    // Twitter post ID
}
```

---

## üîß Common Operations

### Service Management
```bash
pm2 list                          # View all services
pm2 restart api-manager           # Restart API
pm2 logs tweet-worker --lines 50  # View logs
```

### Manual Scraping
```bash
./scripts/vps-scrape.sh           # Full pipeline
node scrapers/run-scraper.js      # Cricbuzz only
node scrapers/content-enhancer-claude.js  # AI enhance
```

### Twitter
```bash
npm run tweet:dry                 # Test (no posting)
npm run tweet:single              # Post one tweet
```

### Database
```bash
node scripts/prune-news.js        # Remove old articles
node scripts/clear_news_cache.js  # Clear cache
```

### Logs
```bash
tail -f /var/log/cricket-scraper.log  # Cron output
pm2 logs                              # PM2 services
```

---

## üîë External Dependencies

| Service | Purpose | Config Key |
|---------|---------|------------|
| **Supabase PostgreSQL** | Primary database | `DATABASE_URL` |
| **Upstash Redis** | Live scores cache | `UPSTASH_REDIS_*` |
| **Gemini 3 Flash** | AI content enhancement | `ai.urtechy.com` proxy |
| **Twitter API v2** | Auto-posting | `TWITTER_*` |
| **RapidAPI Cricbuzz** | Stats/rankings | `RAPIDAPI_CRICBUZZ_KEY*` (5 rotating) |
| **Discord Webhooks** | Notifications | `DISCORD_WEBHOOK_URL` |

---

## ‚ö†Ô∏è Important Notes

1. **Two Projects Exist:**
   - `api-manager` (this) ‚Üí PostgreSQL (Supabase)
   - `news-trading-scrape` (legacy) ‚Üí SQLite (local)

2. **Rate Limits:**
   - Twitter: 8 tweets/day max (FREE tier)
   - RapidAPI: 5 keys rotating for rankings

3. **Content Flow:**
   ```
   Scrapers ‚Üí NewsArticle ‚Üí Gemini Flash Enhancer ‚Üí EnhancedContent ‚Üí Tweet Worker ‚Üí Twitter
   ```

4. **Live Scores Flow:**
   ```
   live-score-worker (60s) ‚Üí Upstash Redis ‚Üí /live-scores endpoint
   ```

---

## üêõ Troubleshooting

| Issue | Check |
|-------|-------|
| Live scores stale | `pm2 logs live-score-worker` |
| Tweets not posting | `TWEET_ENABLED=true` in .env.local |
| Scraper failing | Check `/var/log/cricket-scraper.log` |
| API 500 errors | `pm2 logs api-manager` |
| No enhanced content | Run `node scrapers/content-enhancer-claude.js` |
