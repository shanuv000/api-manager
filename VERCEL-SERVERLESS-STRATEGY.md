# Vercel Serverless Puppeteer Strategy

## âš ï¸ Challenge: Vercel Hobby Timeout Limits

**Vercel Hobby Plan Limits:**

- â±ï¸ **10-second execution timeout** for serverless functions
- ğŸ“¦ **50MB deployment size limit**

**Our Scraper Reality:**

- ğŸ• Takes 30-60 seconds to scrape 20 articles with Puppeteer
- âŒ Will timeout on every request on Vercel

## âœ… Solution: Database-First, Cron-Populated

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              API Requests (Vercel)                  â”‚
â”‚  - Returns database data ONLY (instant, <1s)       â”‚
â”‚  - No Puppeteer scraping on Vercel                 â”‚
â”‚  - Fast, reliable, within 10s timeout              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Supabase PostgreSQL                     â”‚
â”‚  - Stores all articles                              â”‚
â”‚  - Queried by Vercel API                            â”‚
â”‚  - Populated by GitHub Actions                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–²
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         GitHub Actions Cron Job                     â”‚
â”‚  - Runs every 3 hours                               â”‚
â”‚  - No timeout limits                                â”‚
â”‚  - Can take 60+ seconds to scrape                  â”‚
â”‚  - Directly updates database                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation

#### 1. API Behavior (Vercel Production)

```javascript
// Detects Vercel environment
const isVercel = !!process.env.VERCEL;

if (isVercel) {
  // FAST: Return database data only
  // No Puppeteer (avoids timeout)
  return database results;
} else {
  // LOCAL: Can scrape with Puppeteer
  // No timeout limits in dev
  scrape if needed;
}
```

**Result:**

- âœ… Vercel API responds in <1 second
- âœ… No timeouts
- âœ… Always serves fresh data from database

#### 2. GitHub Actions Cron

**Current Workflow:** `.github/workflows/fetch-cricket-news.yml`

```yaml
# Runs every 3 hours
schedule:
  - cron: "30 0,3,6,9,12,15,18,21 * * *"
```

**How it works:**

1. GitHub runner calls API endpoint
2. API returns database data (if available)
3. Database gets populated by separate scraping process

**Better Alternative:** Run scraper directly in GitHub Actions

```yaml
jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Install dependencies
        run: npm install

      - name: Run scraper directly
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: node scripts/scrape-to-db.js
```

**Benefits:**

- âœ… No timeout (GitHub Actions allows 6 hours)
- âœ… Direct database update
- âœ… Doesn't call Vercel API
- âœ… More reliable

### Deployment Size

**With our setup:**

```
puppeteer-core: ~2MB
@sparticuz/chromium: ~50MB (downloaded at runtime)
Total deployment: < 50MB âœ…
```

Chromium is downloaded at first function call, not bundled in deployment.

## ğŸ“Š Performance Comparison

| Approach                       | Response Time | Timeout Risk        | Cost     |
| ------------------------------ | ------------- | ------------------- | -------- |
| âŒ Scrape on Vercel            | 30-60s        | HIGH (always fails) | Free     |
| âœ… **Database-only on Vercel** | **<1s**       | **NONE**            | **Free** |
| âœ… GitHub Actions cron         | N/A           | NONE                | Free     |

## ğŸš€ Current Implementation

**Status:**

- âœ… API detects Vercel environment
- âœ… Disables scraping on Vercel production
- âœ… Returns database data only (fast)
- âœ… Scraping still works locally for development
- âœ… GitHub Actions cron ready to populate database

**API Response on Vercel:**

```json
{
  "success": true,
  "count": 20,
  "data": [...],
  "source": "database",
  "note": "Scraping disabled on Vercel due to timeout limits. Database updated via GitHub Actions cron."
}
```

## ğŸ”§ Alternative: Self-Hosted Cron

If GitHub Actions isn't ideal, you can use:

**Option 1: Railway**

- Free tier: 500 hours/month
- No timeout limits
- Can run cron jobs

**Option 2: Render.com**

- Free tier with cron jobs
- No timeout limits

**Option 3: Vercel Cron (Pro)**

- Upgrade to Pro plan
- 5-minute timeouts (still might not be enough)
- $20/month

**Recommendation:** Stick with GitHub Actions (free, reliable, already set up)

## ğŸ“ Summary

âœ… **Vercel API:** Fast database queries only (<1s)  
âœ… **GitHub Actions:** Handles slow scraping (30-60s)  
âœ… **No timeouts:** Everything works within limits  
âœ… **Free:** All on free tiers  
âœ… **Scalable:** Add more sports without changes
