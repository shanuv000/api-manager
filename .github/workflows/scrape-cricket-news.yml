name: Scrape Cricket News

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  workflow_dispatch:  # Manual trigger

jobs:
  scrape-and-store:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      
      - name: Install dependencies
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          DIRECT_URL: ${{ secrets.DIRECT_URL }}
        run: npm install
      
      - name: Install Chromium dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser || sudo snap install chromium
      
      - name: Run scraper and populate database
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          DIRECT_URL: ${{ secrets.DIRECT_URL }}
        run: |
          echo "üèè Starting Cricbuzz news scraper..."
          node scrapers/run-scraper.js
      
      - name: Summary
        run: |
          echo "‚úÖ Scraping completed!"
          echo "Articles are now in Supabase database"
          echo "API endpoint: https://api-sync.vercel.app/api/cricket/news"
